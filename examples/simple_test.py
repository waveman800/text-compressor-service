"""
ç®€å•æµ‹è¯•ï¼šé€æ˜ä»£ç†æ¨¡å¼æ¼”ç¤º
"""

import requests
import json

# å‹ç¼©æœåŠ¡åœ°å€
COMPRESSOR_URL = "http://localhost:8000"

print("="*60)
print("æ–‡æœ¬å‹ç¼©æœåŠ¡ - é€æ˜ä»£ç†æ¨¡å¼æ¼”ç¤º")
print("="*60)

# 1. å¥åº·æ£€æŸ¥
print("\n1. å¥åº·æ£€æŸ¥")
try:
    response = requests.get(f"{COMPRESSOR_URL}/health")
    if response.status_code == 200:
        print("âœ… å‹ç¼©æœåŠ¡è¿è¡Œæ­£å¸¸")
        print(f"   å“åº”: {response.json()}")
    else:
        print(f"âŒ å‹ç¼©æœåŠ¡å¼‚å¸¸: {response.status_code}")
        exit(1)
except Exception as e:
    print(f"âŒ æ— æ³•è¿æ¥åˆ°å‹ç¼©æœåŠ¡: {e}")
    exit(1)

# 2. ç›´æ¥å‹ç¼©æµ‹è¯•
print("\n2. ç›´æ¥å‹ç¼©æµ‹è¯•")
long_text = """
äººå·¥æ™ºèƒ½ï¼ˆArtificial Intelligenceï¼Œç®€ç§°AIï¼‰æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œ
å®ƒä¼å›¾äº†è§£æ™ºèƒ½çš„å®è´¨ï¼Œå¹¶ç”Ÿäº§å‡ºä¸€ç§æ–°çš„èƒ½ä»¥äººç±»æ™ºèƒ½ç›¸ä¼¼çš„æ–¹å¼åšå‡ºååº”çš„æ™ºèƒ½æœºå™¨ã€‚
è¯¥é¢†åŸŸçš„ç ”ç©¶åŒ…æ‹¬æœºå™¨äººã€è¯­è¨€è¯†åˆ«ã€å›¾åƒè¯†åˆ«ã€è‡ªç„¶è¯­è¨€å¤„ç†å’Œä¸“å®¶ç³»ç»Ÿç­‰ã€‚

äººå·¥æ™ºèƒ½ä»è¯ç”Ÿä»¥æ¥ï¼Œç†è®ºå’ŒæŠ€æœ¯æ—¥ç›Šæˆç†Ÿï¼Œåº”ç”¨é¢†åŸŸä¹Ÿä¸æ–­æ‰©å¤§ï¼Œ
å¯ä»¥è®¾æƒ³ï¼Œæœªæ¥äººå·¥æ™ºèƒ½å¸¦æ¥çš„ç§‘æŠ€äº§å“ï¼Œå°†ä¼šæ˜¯äººç±»æ™ºæ…§çš„"å®¹å™¨"ã€‚
äººå·¥æ™ºèƒ½å¯ä»¥å¯¹äººçš„æ„è¯†ã€æ€ç»´çš„ä¿¡æ¯è¿‡ç¨‹çš„æ¨¡æ‹Ÿã€‚
"""

try:
    response = requests.post(
        f"{COMPRESSOR_URL}/compress/text",
        json={
            "text": long_text,
            "current_prompt": "è¯·æ€»ç»“è¿™æ®µæ–‡å­—",
            "max_new_tokens": 50,
            "session_len": 200
        }
    )
    
    if response.status_code == 200:
        result = response.json()
        print("âœ… å‹ç¼©æˆåŠŸ")
        print(f"   åŸå§‹tokens: {result['original_length']}")
        print(f"   å‹ç¼©åtokens: {result['compressed_length']}")
        print(f"   å‹ç¼©æ¯”: {result['compressed_length']/result['original_length']:.2%}")
    else:
        print(f"âŒ å‹ç¼©å¤±è´¥: {response.status_code}")
except Exception as e:
    print(f"âŒ å‹ç¼©è¯·æ±‚å¤±è´¥: {e}")

# 3. èŠå¤©å†å²å‹ç¼©æµ‹è¯•
print("\n3. èŠå¤©å†å²å‹ç¼©æµ‹è¯•")
chat_history = [
    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIåŠ©æ‰‹ã€‚"},
    {"role": "user", "content": "ä½ å¥½ï¼"},
    {"role": "assistant", "content": "ä½ å¥½ï¼æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ"},
    {"role": "user", "content": "è¯·ä»‹ç»ä¸€ä¸‹Pythonã€‚"},
]

try:
    response = requests.post(
        f"{COMPRESSOR_URL}/compress/chat",
        json={
            "chat_history": chat_history,
            "current_prompt": "è¯·ä»‹ç»ä¸€ä¸‹Pythonã€‚",
            "max_new_tokens": 256,
            "session_len": 500
        }
    )
    
    if response.status_code == 200:
        result = response.json()
        print("âœ… èŠå¤©å†å²å‹ç¼©æˆåŠŸ")
        print(f"   åŸå§‹tokens: {result['original_length']}")
        print(f"   å‹ç¼©åtokens: {result['compressed_length']}")
        print(f"   å‹ç¼©æ¯”: {result['compressed_length']/result['original_length']:.2%}")
    else:
        print(f"âŒ èŠå¤©å†å²å‹ç¼©å¤±è´¥: {response.status_code}")
except Exception as e:
    print(f"âŒ èŠå¤©å†å²å‹ç¼©è¯·æ±‚å¤±è´¥: {e}")

# 4. é€æ˜ä»£ç†æ¨¡å¼è¯´æ˜
print("\n4. é€æ˜ä»£ç†æ¨¡å¼è¯´æ˜")
print("="*60)
print("ğŸ¯ æ ¸å¿ƒä¼˜åŠ¿ï¼šå®¢æˆ·ç«¯é›¶æ„ŸçŸ¥")
print("="*60)
print()
print("âŒ æ–¹æ¡ˆ1ï¼šæ‰‹åŠ¨ä¸¤æ­¥è°ƒç”¨ï¼ˆå¤æ‚ï¼‰")
print("   ç¬¬1æ­¥ï¼šè°ƒç”¨å‹ç¼©æœåŠ¡")
print("   ç¬¬2æ­¥ï¼šæ‰‹åŠ¨è°ƒç”¨å¤§æ¨¡å‹æœåŠ¡")
print("   é—®é¢˜ï¼šéœ€è¦å®¢æˆ·ç«¯å¤„ç†ä¸¤æ¬¡è¯·æ±‚ï¼Œä»£ç å¤æ‚")
print()
print("âŒ æ–¹æ¡ˆ2ï¼šè¯·æ±‚æŠ¥æ–‡åŠ æ ‡è¯†ï¼ˆä¾µå…¥ï¼‰")
print("   åœ¨è¯·æ±‚ä¸­æ·»åŠ  compress: true")
print("   é—®é¢˜ï¼šéœ€è¦ä¿®æ”¹å¤§æ¨¡å‹æœåŠ¡çš„ä»£ç ")
print()
print("âœ… æ–¹æ¡ˆ3ï¼šé€æ˜ä»£ç†æ¨¡å¼ï¼ˆæ¨èï¼‰")
print("   å®¢æˆ·ç«¯åªéœ€åƒè°ƒç”¨æ™®é€šOpenAI APIä¸€æ ·")
print("   å‹ç¼©æœåŠ¡è‡ªåŠ¨å¤„ç†å‹ç¼©å’Œè½¬å‘")
print("   å¯¹å®¢æˆ·ç«¯å®Œå…¨é€æ˜ï¼")
print()
print("="*60)
print("ä½¿ç”¨é€æ˜ä»£ç†æ¨¡å¼")
print("="*60)
print()
print("æ­¥éª¤1ï¼šé…ç½® .env æ–‡ä»¶")
print("  OPENAI_API_BASE_URL=http://your-model-service/v1")
print("  OPENAI_API_KEY=your-api-key")
print()
print("æ­¥éª¤2ï¼šå®¢æˆ·ç«¯ä»£ç ï¼ˆå®Œå…¨ä¸éœ€è¦ä¿®æ”¹ï¼‰")
print("""
import requests

response = requests.post(
    "http://localhost:8000/v1/chat/completions",  # å‹ç¼©æœåŠ¡
    json={
        "model": "gpt-3.5-turbo",
        "messages": chat_history,
        "max_tokens": 256
    }
)

result = response.json()
print(result['choices'][0]['message']['content'])
""")
print()
print("ğŸ¯ å…³é”®ç‚¹ï¼šåªéœ€è¦æ”¹å˜URLï¼Œå…¶ä»–ä»£ç å®Œå…¨ç›¸åŒï¼")
print()
print("="*60)
print("å†…éƒ¨å¤„ç†æµç¨‹ï¼ˆå¯¹å®¢æˆ·ç«¯é€æ˜ï¼‰")
print("="*60)
print("1. å‹ç¼©æœåŠ¡æ¥æ”¶è¯·æ±‚")
print("2. åˆ†æèŠå¤©å†å²çš„tokenæ•°é‡")
print("3. å¦‚æœè¶…è¿‡ä¸Šä¸‹æ–‡çª—å£ï¼Œè‡ªåŠ¨å‹ç¼©")
print("4. æ„å»ºæ–°çš„è¯·æ±‚ï¼ˆä½¿ç”¨å‹ç¼©åçš„èŠå¤©å†å²ï¼‰")
print("5. è½¬å‘åˆ°çœŸå®æ¨¡å‹æœåŠ¡")
print("6. è¿”å›æ¨¡å‹å“åº”ç»™å®¢æˆ·ç«¯")
print()
print("âœ… å®¢æˆ·ç«¯å®Œå…¨ä¸çŸ¥é“å‹ç¼©çš„å­˜åœ¨ï¼")
